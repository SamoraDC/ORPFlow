{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# D4PG + EVT Training Pipeline\n\n## ‚öôÔ∏è Runtime: L4 GPU (~12 CU)\n**Menu: Runtime ‚Üí Change runtime type ‚Üí L4 GPU**\n\n## Anti-Leakage Guarantees\n1. **Per-Symbol Temporal Split** - Each symbol split independently\n2. **RL Trained on Train Data ONLY** - No information from val/test\n3. **EVT Risk Model** - Trained on training period returns only\n4. **Realistic Episode Structure** - Proper environment reset\n\n## Output\n- `trained/d4pg_actor.onnx`\n- `trained/d4pg_actor.pt`\n- `trained/d4pg_metadata.json`\n\n## Note\nTraining takes 3-4 hours due to 200 episodes x 250k+ steps per episode"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available(): print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch onnx onnxruntime-gpu pandas numpy scikit-learn scipy requests tqdm\n",
    "print(\"‚úì Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy import stats\nfrom collections import deque\nfrom pathlib import Path\nimport json, time, random, warnings\nwarnings.filterwarnings('ignore')\n\nTRAINED_DIR = Path(\"trained\")\nTRAINED_DIR.mkdir(parents=True, exist_ok=True)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {DEVICE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import requests\nfrom datetime import datetime, timedelta\nfrom tqdm.notebook import tqdm\n\ndef fetch_klines_sync(symbol, days=90):\n    base_url = \"https://api.binance.com/api/v3/klines\"\n    end_time = datetime.utcnow()\n    start_time = end_time - timedelta(days=days)\n    all_data = []\n    current = start_time\n    while current < end_time:\n        params = {\"symbol\": symbol, \"interval\": \"1m\",\n                  \"startTime\": int(current.timestamp()*1000),\n                  \"endTime\": int(min(current+timedelta(days=1), end_time).timestamp()*1000), \"limit\": 1440}\n        try:\n            resp = requests.get(base_url, params=params, timeout=30)\n            data = resp.json()\n            if isinstance(data, list): all_data.extend(data)\n        except: pass\n        current += timedelta(days=1)\n        time.sleep(0.1)\n    if not all_data: return pd.DataFrame()\n    cols = [\"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"close_time\",\"quote_volume\",\"trades\",\"taker_buy_base\",\"taker_buy_quote\",\"ignore\"]\n    df = pd.DataFrame(all_data, columns=cols)\n    df[\"open_time\"] = pd.to_datetime(df[\"open_time\"], unit=\"ms\")\n    for c in [\"open\",\"high\",\"low\",\"close\",\"volume\",\"quote_volume\",\"taker_buy_base\",\"taker_buy_quote\"]: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n    df[\"symbol\"] = symbol\n    return df.drop_duplicates(subset=[\"open_time\"]).sort_values(\"open_time\")\n\ndef calculate_comprehensive_features(df):\n    \"\"\"Calculate ~150 institutional-grade crypto features\"\"\"\n    df = df.copy()\n    ann_factor = np.sqrt(252 * 24 * 60)\n\n    # 1. RETURNS & PRICE ACTION\n    df[\"log_return\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n    df[\"return_1\"] = df[\"close\"].pct_change(1)\n    for w in [5, 10, 20, 50, 100, 200]:\n        df[f\"return_{w}\"] = df[\"close\"].pct_change(w)\n    for w in [20, 50]:\n        vol = df[\"log_return\"].rolling(w).std()\n        df[f\"sharpe_{w}\"] = df[f\"return_{w}\"] / (vol * np.sqrt(w) + 1e-10)\n\n    # 2. VOLATILITY (multiple estimators)\n    for w in [5, 10, 20, 50, 100]:\n        df[f\"volatility_{w}\"] = df[\"log_return\"].rolling(w).std() * ann_factor\n    for w in [20, 50]:\n        log_hl = np.log(df[\"high\"] / df[\"low\"])\n        df[f\"parkinson_vol_{w}\"] = np.sqrt((1/(4*np.log(2))) * (log_hl**2).rolling(w).mean()) * ann_factor\n        log_co = np.log(df[\"close\"] / df[\"open\"])\n        gk = 0.5 * log_hl**2 - (2*np.log(2) - 1) * log_co**2\n        df[f\"gk_vol_{w}\"] = np.sqrt(gk.rolling(w).mean().abs()) * ann_factor\n    for w in [14, 20, 50]:\n        tr = pd.concat([df[\"high\"] - df[\"low\"], abs(df[\"high\"] - df[\"close\"].shift(1)), abs(df[\"low\"] - df[\"close\"].shift(1))], axis=1).max(axis=1)\n        df[f\"atr_{w}\"] = tr.rolling(w).mean()\n        df[f\"atr_pct_{w}\"] = df[f\"atr_{w}\"] / df[\"close\"] * 100\n    df[\"vol_regime\"] = df[\"volatility_20\"] / (df[\"volatility_100\"] + 1e-10)\n\n    # 3. VOLUME (CVD, VWAP, trades)\n    for w in [5, 10, 20, 50]:\n        df[f\"volume_ma_{w}\"] = df[\"volume\"].rolling(w).mean()\n    df[\"rvol_20\"] = df[\"volume\"] / (df[\"volume\"].rolling(20).mean() + 1e-10)\n    df[\"volume_zscore\"] = (df[\"volume\"] - df[\"volume\"].rolling(50).mean()) / (df[\"volume\"].rolling(50).std() + 1e-10)\n    typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n    for w in [20, 50]:\n        cum_vol = df[\"volume\"].rolling(w).sum()\n        cum_tp_vol = (typical_price * df[\"volume\"]).rolling(w).sum()\n        df[f\"vwap_dist_{w}\"] = (df[\"close\"] - cum_tp_vol/(cum_vol+1e-10)) / (cum_tp_vol/(cum_vol+1e-10)+1e-10) * 100\n    volume_delta = df[\"taker_buy_base\"] - (df[\"volume\"] - df[\"taker_buy_base\"])\n    for w in [10, 20, 50]:\n        df[f\"cvd_{w}\"] = volume_delta.rolling(w).sum()\n        df[f\"cvd_norm_{w}\"] = df[f\"cvd_{w}\"] / (df[\"volume\"].rolling(w).sum() + 1e-10)\n    df[\"dollar_vol_ratio\"] = df[\"quote_volume\"] / (df[\"quote_volume\"].rolling(20).mean() + 1e-10)\n\n    # 4. MICROSTRUCTURE\n    df[\"spread_bps\"] = (df[\"high\"] - df[\"low\"]) / df[\"close\"] * 10000\n    df[\"ofi\"] = df[\"taker_buy_base\"] / (df[\"volume\"] + 1e-10)\n    for w in [10, 20, 50]:\n        df[f\"buy_pressure_{w}\"] = df[\"taker_buy_base\"].rolling(w).sum() / (df[\"volume\"].rolling(w).sum() + 1e-10)\n    df[\"amihud\"] = abs(df[\"return_1\"]) / (df[\"quote_volume\"] / 1e6 + 1e-10)\n\n    # 5. MOMENTUM (MACD, RSI, ADX, etc.)\n    for w in [5, 10, 20, 50, 100]:\n        df[f\"ma_dist_{w}\"] = (df[\"close\"] - df[\"close\"].rolling(w).mean()) / df[\"close\"].rolling(w).mean() * 100\n    ema12 = df[\"close\"].ewm(span=12, adjust=False).mean()\n    ema26 = df[\"close\"].ewm(span=26, adjust=False).mean()\n    df[\"macd\"] = ema12 - ema26\n    df[\"macd_signal\"] = df[\"macd\"].ewm(span=9, adjust=False).mean()\n    df[\"macd_hist\"] = df[\"macd\"] - df[\"macd_signal\"]\n    for w in [7, 14, 21]:\n        delta = df[\"close\"].diff()\n        gain = delta.where(delta > 0, 0).rolling(w).mean()\n        loss = (-delta.where(delta < 0, 0)).rolling(w).mean()\n        df[f\"rsi_{w}\"] = 100 - (100 / (1 + gain/(loss+1e-10)))\n        df[f\"rsi_{w}_norm\"] = (df[f\"rsi_{w}\"] - 50) / 50\n    rsi14 = df[\"rsi_14\"]\n    rsi_min, rsi_max = rsi14.rolling(14).min(), rsi14.rolling(14).max()\n    df[\"stoch_rsi\"] = (rsi14 - rsi_min) / (rsi_max - rsi_min + 1e-10)\n    for w in [14, 21]:\n        highest, lowest = df[\"high\"].rolling(w).max(), df[\"low\"].rolling(w).min()\n        df[f\"williams_r_{w}\"] = -100 * (highest - df[\"close\"]) / (highest - lowest + 1e-10)\n    for w in [14, 20]:\n        plus_dm = df[\"high\"].diff().where(lambda x: x > 0, 0)\n        minus_dm = (-df[\"low\"].diff()).where(lambda x: x > 0, 0)\n        tr = pd.concat([df[\"high\"]-df[\"low\"], abs(df[\"high\"]-df[\"close\"].shift(1)), abs(df[\"low\"]-df[\"close\"].shift(1))], axis=1).max(axis=1)\n        atr = tr.rolling(w).mean()\n        plus_di = 100 * (plus_dm.rolling(w).mean() / (atr + 1e-10))\n        minus_di = 100 * (minus_dm.rolling(w).mean() / (atr + 1e-10))\n        df[f\"adx_{w}\"] = (100 * abs(plus_di - minus_di) / (plus_di + minus_di + 1e-10)).rolling(w).mean()\n    tp = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n    df[\"cci_20\"] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std() + 1e-10)\n\n    # 6. MEAN REVERSION (Bollinger, z-scores)\n    for w in [20, 50]:\n        ma, std = df[\"close\"].rolling(w).mean(), df[\"close\"].rolling(w).std()\n        df[f\"bb_width_{w}\"] = (4 * std) / ma * 100\n        df[f\"bb_position_{w}\"] = (df[\"close\"] - (ma - 2*std)) / (4*std + 1e-10)\n        df[f\"price_zscore_{w}\"] = (df[\"close\"] - ma) / (std + 1e-10)\n\n    # 7. TIME FEATURES\n    hour = df[\"open_time\"].dt.hour\n    dow = df[\"open_time\"].dt.dayofweek\n    df[\"hour_sin\"] = np.sin(2 * np.pi * hour / 24)\n    df[\"hour_cos\"] = np.cos(2 * np.pi * hour / 24)\n    df[\"dow_sin\"] = np.sin(2 * np.pi * dow / 7)\n    df[\"dow_cos\"] = np.cos(2 * np.pi * dow / 7)\n    df[\"is_asia\"] = ((hour >= 0) & (hour < 8)).astype(int)\n    df[\"is_europe\"] = ((hour >= 7) & (hour < 16)).astype(int)\n    df[\"is_us\"] = ((hour >= 13) & (hour < 22)).astype(int)\n    df[\"is_weekend\"] = (dow >= 5).astype(int)\n\n    # 8. STATISTICAL\n    for w in [20, 50]:\n        df[f\"skewness_{w}\"] = df[\"log_return\"].rolling(w).skew()\n        df[f\"kurtosis_{w}\"] = df[\"log_return\"].rolling(w).kurt()\n\n    # 9. PRICE PATTERNS\n    for w in [20, 50, 100]:\n        highest, lowest = df[\"high\"].rolling(w).max(), df[\"low\"].rolling(w).min()\n        df[f\"dist_from_high_{w}\"] = (df[\"close\"] - highest) / highest * 100\n        df[f\"dist_from_low_{w}\"] = (df[\"close\"] - lowest) / lowest * 100\n        df[f\"range_position_{w}\"] = (df[\"close\"] - lowest) / (highest - lowest + 1e-10)\n\n    return df\n\ndef get_feature_columns(df):\n    exclude = [\"open_time\",\"close_time\",\"symbol\",\"ignore\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"quote_volume\",\"trades\",\"taker_buy_base\",\"taker_buy_quote\",\"hour\",\"day_of_week\"]\n    return [c for c in df.columns if c not in exclude and not c.startswith(\"target_\")]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "SYMBOLS = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\", \"SOLUSDT\"]\nprint(\"Collecting data...\")\nall_data = []\nfor sym in tqdm(SYMBOLS):\n    df = fetch_klines_sync(sym, days=90)\n    if len(df) > 0:\n        all_data.append(df)\n        print(f\"  ‚úì {sym}: {len(df):,} rows\")\n\nif not all_data: raise ValueError(\"No data collected!\")\nraw_data = pd.concat(all_data, ignore_index=True)\nprint(f\"\\n‚úì Total: {len(raw_data):,} rows\")\n\n# Per-symbol split - RL uses ONLY training data with comprehensive features\ntrain_dfs = []\nfor sym in raw_data[\"symbol\"].unique():\n    sdf = raw_data[raw_data[\"symbol\"]==sym].copy().sort_values(\"open_time\").reset_index(drop=True)\n    sdf = calculate_comprehensive_features(sdf)  # ~150 features\n    sdf = sdf.replace([np.inf,-np.inf], np.nan).iloc[200:].dropna()  # Extended warmup\n    n = len(sdf)\n    train_end = int(n * 0.70)\n    train_dfs.append(sdf.iloc[:train_end])\n    print(f\"{sym}: {train_end:,} train rows\")\n\ntrain_df = pd.concat(train_dfs).sort_values(\"open_time\").reset_index(drop=True)\nprint(f\"\\n‚úì Total train: {len(train_df):,}\")\nprint(f\"‚úì Features: {len(get_feature_columns(train_df))}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare RL data (TRAIN ONLY)\n",
    "feature_cols = get_feature_columns(train_df)\n",
    "ohlcv_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "rl_features = scaler.fit_transform(train_df[feature_cols].values)\n",
    "rl_ohlcv = train_df[ohlcv_cols].values\n",
    "\n",
    "print(f\"RL Features: {rl_features.shape}\")\n",
    "print(f\"RL OHLCV: {rl_ohlcv.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVT Risk Model\n",
    "class EVTRiskModel:\n",
    "    \"\"\"Extreme Value Theory for tail risk estimation\"\"\"\n",
    "    def __init__(self, threshold_percentile=95.0):\n",
    "        self.threshold_percentile = threshold_percentile\n",
    "        self.losses = []\n",
    "        self.shape = None\n",
    "        self.scale = None\n",
    "        self.threshold = None\n",
    "\n",
    "    def update(self, returns):\n",
    "        losses = -returns[returns < 0]\n",
    "        self.losses.extend(losses.tolist())\n",
    "        if len(self.losses) < 100:\n",
    "            return\n",
    "        losses_array = np.array(self.losses)\n",
    "        self.threshold = np.percentile(losses_array, self.threshold_percentile)\n",
    "        exceedances = losses_array[losses_array > self.threshold] - self.threshold\n",
    "        if len(exceedances) >= 10:\n",
    "            try:\n",
    "                self.shape, _, self.scale = stats.genpareto.fit(exceedances, floc=0)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def var(self, confidence=0.99):\n",
    "        if self.shape is None or self.threshold is None:\n",
    "            return 0.0\n",
    "        n = len(self.losses)\n",
    "        n_exc = sum(1 for l in self.losses if l > self.threshold)\n",
    "        if n_exc == 0:\n",
    "            return 0.0\n",
    "        p = n_exc / n\n",
    "        q = 1 - confidence\n",
    "        if self.shape == 0:\n",
    "            return self.threshold + self.scale * np.log(p / q)\n",
    "        return self.threshold + (self.scale / self.shape) * ((p / q) ** self.shape - 1)\n",
    "\n",
    "    def cvar(self, confidence=0.99):\n",
    "        var = self.var(confidence)\n",
    "        if self.shape is None or self.shape >= 1:\n",
    "            return var\n",
    "        return var / (1 - self.shape) + (self.scale - self.shape * self.threshold) / (1 - self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D4PG Networks\n",
    "class D4PGActor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim=1, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        return self.net(state)\n",
    "\n",
    "\n",
    "class D4PGCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim=1, hidden_dim=256, n_atoms=51):\n",
    "        super().__init__()\n",
    "        self.n_atoms = n_atoms\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim + action_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_atoms)\n",
    "        )\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], dim=-1)\n",
    "        return torch.softmax(self.net(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading Environment\n",
    "class TradingEnvRL:\n",
    "    \"\"\"RL Environment using TRAIN data only\"\"\"\n",
    "    def __init__(self, data, features, initial_balance=100000, transaction_cost=0.0005):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.initial_balance = initial_balance\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0.0\n",
    "        self.step_idx = 0\n",
    "        self.returns = []\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        market = self.features[self.step_idx]\n",
    "        portfolio = np.array([\n",
    "            self.position,\n",
    "            self.balance / self.initial_balance - 1,\n",
    "            np.mean(self.returns[-20:]) if self.returns else 0,\n",
    "            np.std(self.returns[-20:]) if len(self.returns) > 1 else 0\n",
    "        ])\n",
    "        return np.concatenate([market, portfolio])\n",
    "\n",
    "    def step(self, action):\n",
    "        target_pos = float(np.clip(action[0], -1, 1))\n",
    "        pos_change = target_pos - self.position\n",
    "        current_price = self.data[self.step_idx, 3]  # close price\n",
    "        cost = abs(pos_change) * current_price * self.transaction_cost\n",
    "\n",
    "        self.step_idx += 1\n",
    "        done = self.step_idx >= len(self.data) - 1\n",
    "\n",
    "        if not done:\n",
    "            next_price = self.data[self.step_idx, 3]\n",
    "            ret = (next_price - current_price) / current_price\n",
    "            pnl = self.position * ret * self.balance - cost\n",
    "            self.balance += pnl\n",
    "            step_ret = pnl / self.initial_balance\n",
    "            self.returns.append(step_ret)\n",
    "            self.position = target_pos\n",
    "\n",
    "            # Reward: Sharpe-like\n",
    "            if len(self.returns) > 1:\n",
    "                reward = np.mean(self.returns[-20:]) / (np.std(self.returns[-20:]) + 1e-8)\n",
    "            else:\n",
    "                reward = step_ret * 100\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        return self._get_state() if not done else np.zeros_like(self._get_state()), reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING D4PG+EVT (CUDA)\")\n",
    "print(\"=\"*60)\n",
    "print(\"WARNING: This will take 3-4 hours\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "state_dim = rl_features.shape[1] + 4  # features + portfolio state\n",
    "env = TradingEnvRL(rl_ohlcv, rl_features)\n",
    "\n",
    "actor = D4PGActor(state_dim).to(DEVICE)\n",
    "actor_target = D4PGActor(state_dim).to(DEVICE)\n",
    "actor_target.load_state_dict(actor.state_dict())\n",
    "\n",
    "critic = D4PGCritic(state_dim).to(DEVICE)\n",
    "critic_target = D4PGCritic(state_dim).to(DEVICE)\n",
    "critic_target.load_state_dict(critic.state_dict())\n",
    "\n",
    "actor_opt = torch.optim.Adam(actor.parameters(), lr=1e-4)\n",
    "critic_opt = torch.optim.Adam(critic.parameters(), lr=3e-4)\n",
    "\n",
    "evt_model = EVTRiskModel()\n",
    "buffer = deque(maxlen=100000)\n",
    "batch_size = 256\n",
    "gamma = 0.99\n",
    "tau = 0.005\n",
    "episodes = 200\n",
    "\n",
    "start_time = time.time()\n",
    "for ep in range(episodes):\n",
    "    state = env.reset()\n",
    "    ep_reward = 0\n",
    "\n",
    "    while True:\n",
    "        state_t = torch.FloatTensor(state).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            action = actor(state_t).cpu().numpy()[0]\n",
    "\n",
    "        # Exploration noise\n",
    "        action = action + np.random.normal(0, 0.1, size=action.shape)\n",
    "        action = np.clip(action, -1, 1)\n",
    "\n",
    "        next_state, reward, done = env.step(action)\n",
    "        buffer.append((state, action, reward, next_state, done))\n",
    "        evt_model.update(np.array([reward]))\n",
    "\n",
    "        state = next_state\n",
    "        ep_reward += reward\n",
    "\n",
    "        # Training step\n",
    "        if len(buffer) >= batch_size:\n",
    "            batch = random.sample(buffer, batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.FloatTensor(np.array(states)).to(DEVICE)\n",
    "            actions = torch.FloatTensor(np.array(actions)).to(DEVICE)\n",
    "            rewards = torch.FloatTensor(rewards).unsqueeze(1).to(DEVICE)\n",
    "            next_states = torch.FloatTensor(np.array(next_states)).to(DEVICE)\n",
    "            dones = torch.FloatTensor(dones).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "            # Critic update\n",
    "            with torch.no_grad():\n",
    "                next_actions = actor_target(next_states)\n",
    "                target_q = critic_target(next_states, next_actions)\n",
    "\n",
    "            current_q = critic(states, actions)\n",
    "            critic_loss = nn.MSELoss()(current_q.mean(dim=1), rewards.squeeze() + gamma * (1-dones.squeeze()) * target_q.mean(dim=1))\n",
    "\n",
    "            critic_opt.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_opt.step()\n",
    "\n",
    "            # Actor update\n",
    "            actor_loss = -critic(states, actor(states)).mean()\n",
    "\n",
    "            actor_opt.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_opt.step()\n",
    "\n",
    "            # Soft update\n",
    "            for p, tp in zip(actor.parameters(), actor_target.parameters()):\n",
    "                tp.data.copy_(tau * p.data + (1-tau) * tp.data)\n",
    "            for p, tp in zip(critic.parameters(), critic_target.parameters()):\n",
    "                tp.data.copy_(tau * p.data + (1-tau) * tp.data)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if (ep + 1) % 20 == 0:\n",
    "        total_ret = (env.balance - env.initial_balance) / env.initial_balance\n",
    "        print(f\"Episode {ep+1}/{episodes} - Return: {total_ret:.2%}, VaR: {evt_model.var():.4f}\")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\n‚úì Training time: {train_time/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive RL Evaluation with Overfitting Detection\nfrom scipy.stats import spearmanr\n\ndef comprehensive_rl_metrics(env, model_name=\"D4PG\"):\n    \"\"\"Calculate comprehensive metrics for RL model evaluation\"\"\"\n    returns = np.array(env.returns)\n    \n    if len(returns) == 0:\n        print(f\"‚ö†Ô∏è No returns to evaluate for {model_name}\")\n        return {}\n    \n    ann_factor = np.sqrt(252 * 24 * 60)  # minute-level annualization\n    \n    # Basic metrics\n    total_return = (env.balance - env.initial_balance) / env.initial_balance\n    mean_return = np.mean(returns)\n    std_return = np.std(returns)\n    \n    # Risk-adjusted metrics\n    sharpe = (mean_return / (std_return + 1e-10)) * ann_factor\n    \n    # Sortino ratio (downside deviation)\n    downside_returns = returns[returns < 0]\n    downside_std = np.std(downside_returns) if len(downside_returns) > 0 else 1e-10\n    sortino = (mean_return / (downside_std + 1e-10)) * ann_factor\n    \n    # Maximum Drawdown\n    cumulative = np.cumsum(returns)\n    running_max = np.maximum.accumulate(cumulative)\n    drawdowns = running_max - cumulative\n    max_dd = np.max(drawdowns) if len(drawdowns) > 0 else 0\n    \n    # Calmar ratio\n    calmar = total_return / (max_dd + 1e-10) if max_dd > 0 else 0\n    \n    # Win rate & profit factor\n    wins = returns[returns > 0]\n    losses = returns[returns < 0]\n    win_rate = len(wins) / len(returns) if len(returns) > 0 else 0\n    profit_factor = abs(np.sum(wins) / (np.sum(losses) + 1e-10)) if len(losses) > 0 else 0\n    \n    # Tail risk metrics\n    var_95 = np.percentile(returns, 5)\n    var_99 = np.percentile(returns, 1)\n    cvar_95 = np.mean(returns[returns <= var_95]) if len(returns[returns <= var_95]) > 0 else 0\n    \n    # Stability metrics\n    returns_first_half = returns[:len(returns)//2]\n    returns_second_half = returns[len(returns)//2:]\n    sharpe_first = (np.mean(returns_first_half) / (np.std(returns_first_half) + 1e-10)) * ann_factor if len(returns_first_half) > 0 else 0\n    sharpe_second = (np.mean(returns_second_half) / (np.std(returns_second_half) + 1e-10)) * ann_factor if len(returns_second_half) > 0 else 0\n    sharpe_stability = 1 - abs(sharpe_first - sharpe_second) / (abs(sharpe_first) + abs(sharpe_second) + 1e-10)\n    \n    metrics = {\n        \"total_return\": total_return,\n        \"mean_return\": mean_return,\n        \"std_return\": std_return,\n        \"sharpe\": sharpe,\n        \"sortino\": sortino,\n        \"max_drawdown\": max_dd,\n        \"calmar\": calmar,\n        \"win_rate\": win_rate,\n        \"profit_factor\": profit_factor,\n        \"var_95\": var_95,\n        \"var_99\": var_99,\n        \"cvar_95\": cvar_95,\n        \"sharpe_stability\": sharpe_stability,\n        \"n_trades\": len(returns)\n    }\n    \n    return metrics\n\ndef print_rl_metrics(metrics, model_name=\"D4PG\"):\n    \"\"\"Print formatted metrics\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"{model_name} COMPREHENSIVE EVALUATION\")\n    print(f\"{'='*60}\")\n    \n    print(f\"\\nüìä RETURN METRICS:\")\n    print(f\"  Total Return:     {metrics['total_return']:.4%}\")\n    print(f\"  Mean Return:      {metrics['mean_return']:.6f}\")\n    print(f\"  Std Return:       {metrics['std_return']:.6f}\")\n    \n    print(f\"\\nüìà RISK-ADJUSTED METRICS:\")\n    print(f\"  Sharpe Ratio:     {metrics['sharpe']:.4f}\")\n    print(f\"  Sortino Ratio:    {metrics['sortino']:.4f}\")\n    print(f\"  Calmar Ratio:     {metrics['calmar']:.4f}\")\n    \n    print(f\"\\nüìâ RISK METRICS:\")\n    print(f\"  Max Drawdown:     {metrics['max_drawdown']:.4%}\")\n    print(f\"  VaR 95%:          {metrics['var_95']:.6f}\")\n    print(f\"  VaR 99%:          {metrics['var_99']:.6f}\")\n    print(f\"  CVaR 95%:         {metrics['cvar_95']:.6f}\")\n    \n    print(f\"\\nüéØ TRADING METRICS:\")\n    print(f\"  Win Rate:         {metrics['win_rate']:.2%}\")\n    print(f\"  Profit Factor:    {metrics['profit_factor']:.4f}\")\n    print(f\"  Total Trades:     {metrics['n_trades']:,}\")\n    \n    print(f\"\\nüî¨ STABILITY METRICS:\")\n    print(f\"  Sharpe Stability: {metrics['sharpe_stability']:.4f}\")\n\ndef overfitting_analysis_rl(metrics, evt_model):\n    \"\"\"Analyze potential overfitting in RL model\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"OVERFITTING ANALYSIS\")\n    print(f\"{'='*60}\")\n    \n    warnings = []\n    \n    # Check for unrealistic metrics\n    if metrics['sharpe'] > 3.0:\n        warnings.append(f\"‚ö†Ô∏è HIGH SHARPE ({metrics['sharpe']:.2f}) - Possible overfitting or look-ahead bias\")\n    \n    if metrics['win_rate'] > 0.60:\n        warnings.append(f\"‚ö†Ô∏è HIGH WIN RATE ({metrics['win_rate']:.2%}) - Check for data leakage\")\n    \n    if metrics['sharpe_stability'] < 0.5:\n        warnings.append(f\"‚ö†Ô∏è LOW STABILITY ({metrics['sharpe_stability']:.2f}) - Performance not consistent across time\")\n    \n    if metrics['profit_factor'] > 3.0:\n        warnings.append(f\"‚ö†Ô∏è HIGH PROFIT FACTOR ({metrics['profit_factor']:.2f}) - Suspiciously good\")\n    \n    if metrics['max_drawdown'] < 0.01:\n        warnings.append(f\"‚ö†Ô∏è VERY LOW DRAWDOWN ({metrics['max_drawdown']:.4%}) - Unrealistic for volatile assets\")\n    \n    # EVT consistency check\n    if evt_model.var() > 0:\n        evt_var = evt_model.var()\n        empirical_var = abs(metrics['var_99'])\n        if abs(evt_var - empirical_var) / (empirical_var + 1e-10) > 0.5:\n            warnings.append(f\"‚ö†Ô∏è EVT-EMPIRICAL VAR MISMATCH - EVT: {evt_var:.6f} vs Empirical: {empirical_var:.6f}\")\n    \n    if len(warnings) == 0:\n        print(\"‚úÖ No obvious overfitting signals detected\")\n        print(\"   - Sharpe ratio in realistic range\")\n        print(\"   - Win rate not suspiciously high\")\n        print(\"   - Performance stable across time\")\n    else:\n        for w in warnings:\n            print(w)\n    \n    # Final verdict\n    print(f\"\\nüìã VERDICT:\")\n    if len(warnings) <= 1:\n        print(\"‚úÖ Model appears well-calibrated for production\")\n    elif len(warnings) <= 3:\n        print(\"‚ö†Ô∏è Some concerns - recommend additional validation\")\n    else:\n        print(\"‚ùå Multiple overfitting signals - DO NOT deploy without investigation\")\n    \n    return warnings\n\n# Run evaluation\nmetrics = comprehensive_rl_metrics(env, \"D4PG+EVT\")\nprint_rl_metrics(metrics, \"D4PG+EVT\")\noverfitting_warnings = overfitting_analysis_rl(metrics, evt_model)\n\n# Save metrics\nimport json\neval_metrics = {\n    **metrics,\n    \"evt_var_99\": float(evt_model.var()),\n    \"evt_cvar_99\": float(evt_model.cvar()),\n    \"overfitting_warnings\": len(overfitting_warnings)\n}\nwith open(TRAINED_DIR / \"d4pg_evaluation.json\", \"w\") as f:\n    json.dump(eval_metrics, f, indent=2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export ONNX (FIXED: opset_version=15 for Colab compatibility, save to trained/)\nactor.eval()\ndummy_state = torch.randn(1, state_dim).to(DEVICE)\n\n# Save directly to trained/ directory\nonnx_path = TRAINED_DIR / \"d4pg_actor.onnx\"\ntorch.onnx.export(\n    actor, dummy_state, str(onnx_path),\n    input_names=[\"state\"], output_names=[\"action\"],\n    dynamic_axes={\"state\": {0: \"batch\"}, \"action\": {0: \"batch\"}},\n    opset_version=15  # FIXED: Changed from 17 to 15 for Colab ONNX compatibility\n)\n\nimport onnx\nonnx.checker.check_model(onnx.load(str(onnx_path)))\nprint(f\"‚úì ONNX saved: {onnx_path}\")\n\n# Metadata\nmetadata = {\n    \"model_type\": \"d4pg_actor\",\n    \"state_dim\": state_dim,\n    \"action_dim\": 1,\n    \"evt_metrics\": {\"var_99\": float(evt_model.var()), \"cvar_99\": float(evt_model.cvar())},\n    \"train_time_hours\": train_time / 3600,\n    \"evaluation\": eval_metrics\n}\nwith open(TRAINED_DIR / \"d4pg_metadata.json\", \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\n# Save PyTorch\ntorch.save(actor.state_dict(), TRAINED_DIR / \"d4pg_actor.pt\")\nprint(\"\\n‚úì D4PG+EVT TRAINING COMPLETE!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}