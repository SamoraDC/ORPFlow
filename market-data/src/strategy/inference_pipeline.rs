//! Inference Pipeline Module
//!
//! High-performance inference pipeline that integrates:
//! - Microstructure feature calculation
//! - NSMI regime detection and feature augmentation
//! - Model ensemble predictions with dynamic weight adjustment
//!
//! Performance characteristics:
//! - Zero allocations in hot path (pre-allocated buffers)
//! - Inline critical functions for optimal codegen
//! - Thread-safe for async runtime integration
//! - Profile-friendly (array-based lookups, not HashMap)

// Allow dead_code - module is compiled with ml feature but not all functions are used yet
#![allow(dead_code)]

use std::collections::HashMap;
use std::path::Path;

use anyhow::{Context, Result};
use rust_decimal::Decimal;
use serde::{Deserialize, Serialize};
use tracing::{info, trace};

use super::features::{FeatureSnapshot, MicrostructureFeatures};
use super::ml_inference::{FeatureBuffer, ModelEnsemble, ModelType};
use super::models::Side;
use super::nsmi::{NSMIConfig, NSMIFeatures, NSMIResult, NSMIState};
use crate::orderbook::OrderBookState;

/// Configuration for the inference pipeline
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    /// Sequence length for DL models (LSTM, CNN)
    pub sequence_length: usize,
    /// How much NSMI affects model weights (0.0 = none, 1.0 = full)
    pub nsmi_weight: f32,
    /// Expected raw feature dimension (before NSMI augmentation)
    pub feature_dim: usize,
    /// Enable NSMI regime detection
    pub enable_nsmi: bool,
    /// NSMI half-life for exponential weighting
    pub nsmi_half_life: f64,
    /// Minimum confidence threshold for signals
    pub min_confidence: f32,
    /// Minimum samples before generating signals
    pub warmup_samples: usize,
    /// Window size for microstructure features
    pub feature_window_size: usize,
    /// Volatility calculation window
    pub volatility_window: usize,
    /// Momentum calculation window
    pub momentum_window: usize,
}

impl Default for InferenceConfig {
    fn default() -> Self {
        Self {
            sequence_length: 60,
            nsmi_weight: 0.3,
            feature_dim: 20,
            enable_nsmi: true,
            nsmi_half_life: 100.0,
            min_confidence: 0.6,
            warmup_samples: 100,
            feature_window_size: 200,
            volatility_window: 20,
            momentum_window: 10,
        }
    }
}

/// Trading signal generated by the inference pipeline
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TradingSignal {
    /// Symbol for the signal
    pub symbol: String,
    /// Predicted direction (-1.0 = sell, +1.0 = buy)
    pub direction: f32,
    /// Signal strength (0.0 to 1.0)
    pub strength: f32,
    /// Confidence based on model agreement and NSMI stability
    pub confidence: f32,
    /// Suggested side
    pub side: Side,
    /// Timestamp of the signal
    pub timestamp: u64,
    /// Regime identifier
    pub regime: u64,
}

impl TradingSignal {
    /// Create a new trading signal
    #[inline]
    pub fn new(symbol: String, direction: f32, strength: f32, confidence: f32, timestamp: u64, regime: u64) -> Self {
        let side = if direction > 0.0 { Side::Buy } else { Side::Sell };
        Self {
            symbol,
            direction,
            strength,
            confidence,
            side,
            timestamp,
            regime,
        }
    }

    /// Check if signal is actionable
    #[inline]
    pub fn is_actionable(&self, min_confidence: f32) -> bool {
        self.confidence >= min_confidence && self.strength > 0.1
    }
}

/// Result of inference pipeline update
#[derive(Debug, Clone)]
pub struct InferenceResult {
    /// Ensemble prediction (-1.0 to +1.0)
    pub prediction: f32,
    /// Confidence based on model agreement + NSMI stability
    pub confidence: f32,
    /// How much NSMI changed the signal (0.0 = no change)
    pub nsmi_adjustment: f32,
    /// Model weights used for this prediction
    pub model_weights: [f32; 6],
    /// Current regime identifier string
    pub regime: String,
    /// Whether a regime change was detected
    pub regime_change_detected: bool,
    /// NSMI features used
    pub nsmi_features: Option<NSMIFeatures>,
    /// Timestamp
    pub timestamp: u64,
}

impl Default for InferenceResult {
    fn default() -> Self {
        Self {
            prediction: 0.0,
            confidence: 0.0,
            nsmi_adjustment: 0.0,
            model_weights: [0.0; 6],
            regime: "unknown".to_string(),
            regime_change_detected: false,
            nsmi_features: None,
            timestamp: 0,
        }
    }
}

/// Pre-allocated feature vector for zero-allocation hot path
struct FeatureVector {
    /// Raw features buffer
    raw: Vec<f64>,
    /// Float32 features for ML models
    raw_f32: Vec<f32>,
    /// Augmented features (raw + NSMI)
    augmented: Vec<f32>,
    /// Dimension of raw features
    dim: usize,
}

impl FeatureVector {
    fn new(dim: usize) -> Self {
        let nsmi_dim = NSMIFeatures::NUM_FEATURES;
        Self {
            raw: vec![0.0; dim],
            raw_f32: vec![0.0; dim],
            augmented: vec![0.0; dim + nsmi_dim],
            dim,
        }
    }

    /// Extract features from FeatureSnapshot into pre-allocated buffer
    #[inline(always)]
    fn extract_from_snapshot(&mut self, snapshot: &FeatureSnapshot) {
        // Map snapshot fields to feature vector
        // Using array indices for zero-allocation
        let mid_price = snapshot.mid_price
            .map(|d| d.try_into().unwrap_or(0.0))
            .unwrap_or(0.0);

        self.raw[0] = snapshot.imbalance.unwrap_or(0.0);
        self.raw[1] = snapshot.weighted_imbalance.unwrap_or(0.0);
        self.raw[2] = snapshot.volatility.unwrap_or(0.0);
        self.raw[3] = snapshot.momentum.unwrap_or(0.0);
        self.raw[4] = snapshot.imbalance_momentum.unwrap_or(0.0);
        self.raw[5] = snapshot.imbalance_z.unwrap_or(0.0);
        self.raw[6] = snapshot.volatility_z.unwrap_or(0.0);
        self.raw[7] = snapshot.volume_ratio.unwrap_or(1.0);
        self.raw[8] = snapshot.spread_bps
            .map(|d| d.try_into().unwrap_or(0.0))
            .unwrap_or(0.0);
        self.raw[9] = mid_price;

        // Derived features
        if self.dim > 10 {
            let bid_depth: f64 = snapshot.bid_depth
                .map(|d| d.try_into().unwrap_or(0.0))
                .unwrap_or(0.0);
            let ask_depth: f64 = snapshot.ask_depth
                .map(|d| d.try_into().unwrap_or(0.0))
                .unwrap_or(0.0);

            self.raw[10] = bid_depth;
            self.raw[11] = ask_depth;
            self.raw[12] = if ask_depth > 0.0 { bid_depth / ask_depth } else { 1.0 };

            // Normalize mid price (log scale)
            self.raw[13] = if mid_price > 0.0 { mid_price.ln() } else { 0.0 };

            // Fill remaining with zeros
            for i in 14..self.dim {
                self.raw[i] = 0.0;
            }
        }

        // Convert to f32 for ML models
        for i in 0..self.dim {
            self.raw_f32[i] = self.raw[i] as f32;
        }
    }

    /// Augment with NSMI features (zero allocation)
    #[inline(always)]
    fn augment_with_nsmi(&mut self, nsmi: &NSMIFeatures) {
        // Copy raw features
        for i in 0..self.dim {
            self.augmented[i] = self.raw_f32[i];
        }

        // Append NSMI features
        let offset = self.dim;
        self.augmented[offset] = nsmi.nonstationarity as f32;
        self.augmented[offset + 1] = nsmi.regime_prob as f32;
        self.augmented[offset + 2] = nsmi.spectral_gap_norm as f32;
        self.augmented[offset + 3] = nsmi.drift_norm as f32;
        self.augmented[offset + 4] = nsmi.dim_ratio as f32;
        self.augmented[offset + 5] = nsmi.regime_stability as f32;
    }

    /// Get raw features as f64 slice
    #[inline]
    fn raw(&self) -> &[f64] {
        &self.raw
    }

    /// Get raw features as f32 slice
    #[inline]
    fn raw_f32(&self) -> &[f32] {
        &self.raw_f32
    }

    /// Get augmented features
    #[inline]
    fn augmented(&self) -> &[f32] {
        &self.augmented[..self.dim + NSMIFeatures::NUM_FEATURES]
    }
}

/// Inference Pipeline - coordinates feature calculation, NSMI, and model inference
pub struct InferencePipeline {
    /// Microstructure feature calculator
    feature_calculator: MicrostructureFeatures,
    /// NSMI state for regime detection
    nsmi: NSMIState,
    /// Model ensemble
    ensemble: ModelEnsemble,
    /// Feature buffer for sequence models
    feature_buffer: FeatureBuffer,
    /// Pipeline configuration
    config: InferenceConfig,
    /// Pre-allocated feature vector
    feature_vector: FeatureVector,
    /// Last NSMI result
    last_nsmi_result: Option<NSMIResult>,
    /// Sample count
    sample_count: u64,
    /// Current symbol being processed
    current_symbol: String,
    /// Last prediction
    last_prediction: f32,
    /// Model weight cache (array for profile-friendly access)
    cached_weights: [f32; 6],
}

impl InferencePipeline {
    /// Create a new inference pipeline
    ///
    /// # Arguments
    /// * `config` - Pipeline configuration
    /// * `model_dir` - Directory containing ONNX models
    ///
    /// # Returns
    /// * Result containing the configured pipeline
    pub fn new(config: InferenceConfig, model_dir: &Path) -> Result<Self> {
        // Initialize NSMI with appropriate dimension
        let nsmi_config = NSMIConfig {
            dimension: config.feature_dim,
            half_life: config.nsmi_half_life,
            warmup_samples: config.warmup_samples,
            ..Default::default()
        };

        let nsmi = NSMIState::new(nsmi_config);

        // Load model ensemble
        let ensemble = ModelEnsemble::new(model_dir)
            .context("Failed to load model ensemble")?;

        // Initialize feature calculator
        let feature_calculator = MicrostructureFeatures::new(
            config.feature_window_size,
            config.volatility_window,
            config.momentum_window,
        );

        // Initialize feature buffer for sequence models
        let feature_buffer = FeatureBuffer::new(
            config.sequence_length,
            config.feature_dim + NSMIFeatures::NUM_FEATURES,
        );

        // Pre-allocate feature vector
        let feature_vector = FeatureVector::new(config.feature_dim);

        info!(
            feature_dim = config.feature_dim,
            sequence_length = config.sequence_length,
            nsmi_enabled = config.enable_nsmi,
            nsmi_weight = config.nsmi_weight,
            "Inference pipeline initialized"
        );

        Ok(Self {
            feature_calculator,
            nsmi,
            ensemble,
            feature_buffer,
            config,
            feature_vector,
            last_nsmi_result: None,
            sample_count: 0,
            current_symbol: String::new(),
            last_prediction: 0.0,
            cached_weights: [0.0; 6],
        })
    }

    /// Process an order book update and run inference
    ///
    /// This is the main HOT PATH. All operations are optimized for minimal latency.
    ///
    /// # Arguments
    /// * `snapshot` - Order book snapshot
    ///
    /// # Returns
    /// * InferenceResult with prediction and metadata
    #[inline]
    pub fn on_orderbook_update(&mut self, snapshot: &OrderBookState) -> InferenceResult {
        self.sample_count += 1;

        // Update microstructure features
        let feature_snapshot = self.feature_calculator.update(
            &snapshot.symbol,
            snapshot.timestamp,
            snapshot.metrics.mid_price,
            snapshot.metrics.imbalance,
            snapshot.metrics.weighted_imbalance,
            snapshot.metrics.spread_bps,
            snapshot.metrics.bid_depth,
            snapshot.metrics.ask_depth,
        );

        // Extract features into pre-allocated buffer
        self.feature_vector.extract_from_snapshot(&feature_snapshot);

        // Update NSMI with raw features
        let nsmi_result = if self.config.enable_nsmi {
            let result = self.nsmi.update(self.feature_vector.raw());
            self.last_nsmi_result = Some(result.clone());
            Some(result)
        } else {
            None
        };

        // Get NSMI features for augmentation
        let nsmi_features = if self.config.enable_nsmi {
            Some(self.nsmi.get_features())
        } else {
            None
        };

        // Augment features with NSMI
        if let Some(ref nsmi_feat) = nsmi_features {
            self.feature_vector.augment_with_nsmi(nsmi_feat);
        }

        // Update feature buffer for sequence models
        self.feature_buffer.push(self.feature_vector.augmented().to_vec());

        // Run inference
        let (prediction, confidence, nsmi_adjustment) = self.run_inference(&nsmi_features);

        // Determine regime string
        let regime = if let Some(ref result) = nsmi_result {
            if result.regime_change_detected {
                format!("regime_{}_transition", result.current_regime)
            } else if result.nonstationarity_score > 0.7 {
                format!("regime_{}_unstable", result.current_regime)
            } else {
                format!("regime_{}_stable", result.current_regime)
            }
        } else {
            "unknown".to_string()
        };

        // Update current symbol
        self.current_symbol = snapshot.symbol.clone();
        self.last_prediction = prediction;

        InferenceResult {
            prediction,
            confidence,
            nsmi_adjustment,
            model_weights: self.cached_weights,
            regime,
            regime_change_detected: nsmi_result
                .as_ref()
                .map(|r| r.regime_change_detected)
                .unwrap_or(false),
            nsmi_features,
            timestamp: snapshot.timestamp,
        }
    }

    /// Process a trade event (for additional feature updates)
    ///
    /// # Arguments
    /// * `price` - Trade price
    /// * `quantity` - Trade quantity
    /// * `is_buyer_maker` - Whether buyer was the maker
    /// * `timestamp` - Trade timestamp
    ///
    /// # Returns
    /// * Updated InferenceResult
    #[inline]
    pub fn on_trade(
        &mut self,
        _price: Decimal,
        _quantity: Decimal,
        _is_buyer_maker: bool,
        _timestamp: u64,
    ) -> InferenceResult {
        // For now, trades don't update the feature state
        // This is a placeholder for future trade-based features
        InferenceResult {
            prediction: self.last_prediction,
            confidence: 0.0,
            nsmi_adjustment: 0.0,
            model_weights: self.cached_weights,
            regime: "trade_update".to_string(),
            regime_change_detected: false,
            nsmi_features: self.last_nsmi_result.as_ref().map(|_| self.nsmi.get_features()),
            timestamp: _timestamp,
        }
    }

    /// Get current trading signal based on latest inference
    #[inline]
    pub fn get_signal(&self) -> Option<TradingSignal> {
        if self.sample_count < self.config.warmup_samples as u64 {
            return None;
        }

        let prediction = self.last_prediction;
        let strength = prediction.abs();
        let confidence = self.calculate_signal_confidence();

        if confidence < self.config.min_confidence {
            return None;
        }

        let regime = self.last_nsmi_result
            .as_ref()
            .map(|r| r.current_regime)
            .unwrap_or(0);

        Some(TradingSignal::new(
            self.current_symbol.clone(),
            prediction,
            strength,
            confidence,
            self.sample_count,
            regime,
        ))
    }

    /// Get current NSMI status
    #[inline]
    pub fn get_nsmi_status(&self) -> Option<NSMIResult> {
        self.last_nsmi_result.clone()
    }

    /// Get current NSMI features
    #[inline]
    pub fn get_nsmi_features(&self) -> Option<NSMIFeatures> {
        if self.config.enable_nsmi {
            Some(self.nsmi.get_features())
        } else {
            None
        }
    }

    /// Check if pipeline is warmed up
    #[inline]
    pub fn is_warmed_up(&self) -> bool {
        self.sample_count >= self.config.warmup_samples as u64
    }

    /// Get sample count
    #[inline]
    pub fn sample_count(&self) -> u64 {
        self.sample_count
    }

    /// Reset pipeline state
    pub fn reset(&mut self) {
        self.feature_calculator.reset();
        self.nsmi.reset();
        self.feature_buffer.clear();
        self.last_nsmi_result = None;
        self.sample_count = 0;
        self.last_prediction = 0.0;
        self.cached_weights = [0.0; 6];
    }

    /// Run inference on current features
    ///
    /// Returns (prediction, confidence, nsmi_adjustment)
    #[inline(always)]
    fn run_inference(&mut self, nsmi_features: &Option<NSMIFeatures>) -> (f32, f32, f32) {
        // Check warmup
        if self.sample_count < self.config.warmup_samples as u64 {
            return (0.0, 0.0, 0.0);
        }

        // Calculate NSMI regime weight
        let regime_weight = if self.config.enable_nsmi {
            self.nsmi.get_regime_weight() as f32
        } else {
            1.0
        };

        // Get base model weights
        let base_weights = self.ensemble.get_weights();

        // Adjust weights by regime
        let nsmi_factor = self.config.nsmi_weight;
        let base_factor = 1.0 - nsmi_factor * (1.0 - regime_weight);

        // Update cached weights (array for profile-friendly access)
        self.update_cached_weights(&base_weights, base_factor, regime_weight);

        // Try ML model prediction first
        let features = if nsmi_features.is_some() {
            self.feature_vector.augmented()
        } else {
            self.feature_vector.raw_f32()
        };

        let prediction = match self.ensemble.predict(features) {
            Ok(pred) => pred,
            Err(e) => {
                trace!("ML prediction failed: {}", e);
                0.0
            }
        };

        // Calculate confidence based on model agreement and regime stability
        let model_confidence = self.calculate_model_confidence(&base_weights, prediction);
        let regime_confidence = regime_weight;
        let confidence = 0.6 * model_confidence + 0.4 * regime_confidence;

        // Calculate NSMI adjustment
        let nsmi_adjustment = 1.0 - regime_weight;

        (prediction, confidence, nsmi_adjustment)
    }

    /// Update cached weights array from HashMap
    #[inline(always)]
    fn update_cached_weights(&mut self, weights: &HashMap<ModelType, f32>, base_factor: f32, regime_weight: f32) {
        // Map ModelType to array index for O(1) access
        // [LightGBM, XGBoost, LSTM, CNN, D4PG, MARL]
        self.cached_weights[0] = weights.get(&ModelType::LightGBM)
            .map(|w| w * (base_factor * 0.9 + 0.1))
            .unwrap_or(0.0);
        self.cached_weights[1] = weights.get(&ModelType::XGBoost)
            .map(|w| w * (base_factor * 0.9 + 0.1))
            .unwrap_or(0.0);
        self.cached_weights[2] = weights.get(&ModelType::Lstm)
            .map(|w| w * base_factor)
            .unwrap_or(0.0);
        self.cached_weights[3] = weights.get(&ModelType::Cnn)
            .map(|w| w * base_factor)
            .unwrap_or(0.0);
        self.cached_weights[4] = weights.get(&ModelType::D4pg)
            .map(|w| w * (base_factor * 0.8 + 0.2 * regime_weight))
            .unwrap_or(0.0);
        self.cached_weights[5] = weights.get(&ModelType::Marl)
            .map(|w| w * (base_factor * 0.8 + 0.2 * regime_weight))
            .unwrap_or(0.0);

        // Normalize
        let total: f32 = self.cached_weights.iter().sum();
        if total > 0.0 {
            for w in &mut self.cached_weights {
                *w /= total;
            }
        }
    }

    /// Calculate model confidence based on weight distribution
    #[inline(always)]
    fn calculate_model_confidence(&self, weights: &HashMap<ModelType, f32>, prediction: f32) -> f32 {
        // Higher confidence when prediction is strong and weights are concentrated
        let pred_strength = prediction.abs().min(1.0);

        // Weight concentration (entropy-like measure)
        let total: f32 = weights.values().sum();
        if total <= 0.0 {
            return 0.0;
        }

        let normalized: Vec<f32> = weights.values().map(|w| w / total).collect();
        let entropy: f32 = -normalized.iter()
            .filter(|&&w| w > 0.0)
            .map(|w| w * w.ln())
            .sum::<f32>();

        // Lower entropy = higher concentration = higher confidence
        let max_entropy = (weights.len() as f32).ln();
        let concentration = if max_entropy > 0.0 {
            1.0 - (entropy / max_entropy)
        } else {
            1.0
        };

        0.5 * pred_strength + 0.5 * concentration
    }

    /// Calculate signal confidence
    #[inline(always)]
    fn calculate_signal_confidence(&self) -> f32 {
        let pred_strength = self.last_prediction.abs().min(1.0);

        let regime_stability = self.last_nsmi_result
            .as_ref()
            .map(|r| 1.0 - r.nonstationarity_score as f32)
            .unwrap_or(0.5);

        // Weighted combination
        0.6 * pred_strength + 0.4 * regime_stability
    }
}

// Thread-safety implementation
unsafe impl Send for InferencePipeline {}
unsafe impl Sync for InferencePipeline {}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::orderbook::{Level, OrderBookMetrics};

    fn create_test_config() -> InferenceConfig {
        InferenceConfig {
            sequence_length: 10,
            nsmi_weight: 0.3,
            feature_dim: 14,
            enable_nsmi: true,
            nsmi_half_life: 50.0,
            min_confidence: 0.3,
            warmup_samples: 10,
            feature_window_size: 50,
            volatility_window: 10,
            momentum_window: 5,
        }
    }

    fn create_test_snapshot(symbol: &str, mid_price: f64, imbalance: f64, timestamp: u64) -> OrderBookState {
        OrderBookState {
            symbol: symbol.to_string(),
            timestamp,
            last_update_id: timestamp,
            bids: vec![Level {
                price: Decimal::try_from(mid_price - 0.5).unwrap(),
                quantity: Decimal::from(10),
            }],
            asks: vec![Level {
                price: Decimal::try_from(mid_price + 0.5).unwrap(),
                quantity: Decimal::from(10),
            }],
            metrics: OrderBookMetrics {
                mid_price: Some(Decimal::try_from(mid_price).unwrap()),
                spread_bps: Some(Decimal::from(2)),
                imbalance: Some(Decimal::try_from(imbalance).unwrap()),
                weighted_imbalance: Some(Decimal::try_from(imbalance * 0.9).unwrap()),
                bid_depth: Decimal::from(100),
                ask_depth: Decimal::from(100),
                bid_levels: 10,
                ask_levels: 10,
            },
        }
    }

    #[test]
    fn test_inference_config_default() {
        let config = InferenceConfig::default();
        assert_eq!(config.sequence_length, 60);
        assert_eq!(config.nsmi_weight, 0.3);
        assert!(config.enable_nsmi);
    }

    #[test]
    fn test_trading_signal_creation() {
        let signal = TradingSignal::new(
            "BTCUSDT".to_string(),
            0.5,
            0.5,
            0.8,
            1000,
            1,
        );

        assert_eq!(signal.symbol, "BTCUSDT");
        assert_eq!(signal.direction, 0.5);
        assert_eq!(signal.side, Side::Buy);
        assert!(signal.is_actionable(0.6));
    }

    #[test]
    fn test_trading_signal_sell() {
        let signal = TradingSignal::new(
            "BTCUSDT".to_string(),
            -0.7,
            0.7,
            0.9,
            1000,
            1,
        );

        assert_eq!(signal.side, Side::Sell);
    }

    #[test]
    fn test_inference_result_default() {
        let result = InferenceResult::default();
        assert_eq!(result.prediction, 0.0);
        assert_eq!(result.confidence, 0.0);
        assert_eq!(result.regime, "unknown");
        assert!(!result.regime_change_detected);
    }

    #[test]
    fn test_feature_vector_creation() {
        let fv = FeatureVector::new(14);
        assert_eq!(fv.dim, 14);
        assert_eq!(fv.raw.len(), 14);
        assert_eq!(fv.raw_f32.len(), 14);
        assert_eq!(fv.augmented.len(), 14 + NSMIFeatures::NUM_FEATURES);
    }

    #[test]
    fn test_feature_vector_extraction() {
        let mut fv = FeatureVector::new(14);

        let snapshot = FeatureSnapshot {
            timestamp: 1000,
            symbol: "BTCUSDT".to_string(),
            mid_price: Some(Decimal::from(50000)),
            spread_bps: Some(Decimal::from(5)),
            imbalance: Some(0.3),
            weighted_imbalance: Some(0.25),
            bid_depth: Some(Decimal::from(100)),
            ask_depth: Some(Decimal::from(80)),
            volume_ratio: Some(1.25),
            volatility: Some(0.02),
            momentum: Some(0.001),
            imbalance_momentum: Some(0.05),
            imbalance_z: Some(1.5),
            volatility_z: Some(-0.5),
        };

        fv.extract_from_snapshot(&snapshot);

        assert!((fv.raw[0] - 0.3).abs() < 0.001); // imbalance
        assert!((fv.raw[1] - 0.25).abs() < 0.001); // weighted_imbalance
        assert!((fv.raw[2] - 0.02).abs() < 0.001); // volatility
    }

    #[test]
    fn test_feature_vector_augmentation() {
        let mut fv = FeatureVector::new(10);

        // Fill raw features
        for i in 0..10 {
            fv.raw_f32[i] = i as f32;
        }

        let nsmi_features = NSMIFeatures {
            nonstationarity: 0.5,
            regime_prob: 0.3,
            spectral_gap_norm: 0.8,
            drift_norm: 0.2,
            dim_ratio: 0.6,
            regime_stability: 0.9,
        };

        fv.augment_with_nsmi(&nsmi_features);

        let augmented = fv.augmented();
        assert_eq!(augmented.len(), 16);

        // Check raw features
        for i in 0..10 {
            assert_eq!(augmented[i], i as f32);
        }

        // Check NSMI features
        assert!((augmented[10] - 0.5).abs() < 0.001);
        assert!((augmented[15] - 0.9).abs() < 0.001);
    }

    #[test]
    fn test_signal_not_actionable_low_confidence() {
        let signal = TradingSignal::new(
            "BTCUSDT".to_string(),
            0.5,
            0.5,
            0.3,  // Low confidence
            1000,
            1,
        );

        assert!(!signal.is_actionable(0.6));
    }

    #[test]
    fn test_signal_not_actionable_low_strength() {
        let signal = TradingSignal::new(
            "BTCUSDT".to_string(),
            0.05,  // Low direction
            0.05,  // Low strength
            0.9,
            1000,
            1,
        );

        assert!(!signal.is_actionable(0.6));
    }
}
