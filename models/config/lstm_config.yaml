# LSTM Training Configuration
# ============================
# Optimized for BTCUSDT 1-minute bars trading

# Data settings
data:
  data_path: "data/processed/features.parquet"
  target_column: "target_return_5"
  sequence_length: 60  # 60 bars (1 hour of 1-min data)

# Model architecture
model:
  hidden_size: 128
  num_layers: 2
  dropout: 0.2
  bidirectional: false
  use_attention: true  # Enable attention mechanism

# Training parameters
training:
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  weight_decay: 1.0e-5
  patience: 15
  gradient_clip: 1.0

  # Learning rate schedule
  lr_scheduler: "cosine"  # Options: cosine, plateau, step
  warmup_epochs: 5
  min_lr: 1.0e-6

# CPCV (Combinatorial Purged Cross-Validation)
cpcv:
  enabled: true
  n_splits: 5
  n_test_groups: 2
  embargo_pct: 0.01
  purge_pct: 0.005

# Optuna hyperparameter optimization
optuna:
  enabled: false
  n_trials: 50
  timeout: 7200

  search_space:
    hidden_size: [64, 128, 256]
    num_layers: [1, 2, 3]
    dropout: [0.1, 0.5]
    learning_rate: [1.0e-5, 1.0e-2]
    batch_size: [32, 64, 128]
    bidirectional: [true, false]

# Output settings
output:
  output_dir: "trained"
  model_name: "lstm_model"
  export_onnx: true

# Device
device: "auto"  # auto, cpu, cuda

# Logging
logging:
  level: "INFO"
  log_to_file: true
  log_file: "logs/lstm_training.log"
